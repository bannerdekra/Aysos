import os
import requests
import json
import time

# æ£€æŸ¥ Google GenAI SDK æ˜¯å¦å¯ç”¨
GENAI_AVAILABLE = False
try:
    # å°è¯•ä¸¤ç§å¯¼å…¥æ–¹å¼
    try:
        from google import genai
        GENAI_AVAILABLE = True
        print("âœ… Google GenAI SDK (genai) å·²åŠ è½½")
    except ImportError:
        import google.generativeai as genai
        GENAI_AVAILABLE = True
        print("âœ… Google GenAI SDK (generativeai) å·²åŠ è½½")
except ImportError:
    print("âŒ Google GenAI SDK æœªå®‰è£…")
    GENAI_AVAILABLE = False

from api_config import load_api_config, get_current_provider_config, get_current_provider_name

# å¯¼å…¥ Gemini ä¸Šä¸‹æ–‡ç®¡ç†å™¨
try:
    from gemini_context_manager import get_gemini_context_manager
    GEMINI_CONTEXT_AVAILABLE = True
    print("âœ… Gemini ä¸Šä¸‹æ–‡ç®¡ç†å™¨å·²å¯¼å…¥")
except ImportError:
    GEMINI_CONTEXT_AVAILABLE = False
    print("âš ï¸ Gemini ä¸Šä¸‹æ–‡ç®¡ç†å™¨æœªå¯¼å…¥")


# ä¿®æ”¹ä¸ºæ­£ç¡®çš„ç›¸å¯¹è·¯å¾„
SPINNER_GIF_URL = os.path.join('SoftWare', 'Image', 'loading', 'loading3.gif')

def get_ai_reply(messages, conversation_id=None, files=None, is_one_time_attachment=None):
    """
    Calls the configured AI API and returns the AI's reply.
    Supports DeepSeek, Gemini (with context and files), and other providers.
    
    Args:
        messages (list): A list of dictionaries, where each dictionary represents a message
                         with 'role' and 'content' keys. This is the chat history.
        conversation_id (str, optional): å¯¹è¯IDï¼Œç”¨äº Gemini ä¸Šä¸‹æ–‡ç®¡ç†
        files (list, optional): æ–‡ä»¶ä¿¡æ¯ï¼Œæ”¯æŒä¸¤ç§æ ¼å¼ï¼š
                               1. å­—å…¸åˆ—è¡¨ [{'path': str, 'mode': str, 'file_id': str}]
                               2. ç®€å•è·¯å¾„åˆ—è¡¨ [str]ï¼ˆé…åˆ is_one_time_attachment å‚æ•°ï¼‰
        is_one_time_attachment (bool, optional): å¦‚æœä¸º Trueï¼Œä½¿ç”¨ Base64 å†…åµŒï¼ˆä»…æœ¬æ¬¡ä½¿ç”¨ï¼‰ï¼›
                                                å¦‚æœä¸º Falseï¼Œä½¿ç”¨ File API ä¸Šä¼ ï¼ˆä¸Šä¸‹æ–‡æŒä¹…åŒ–ï¼‰ã€‚
                                                å½“ files ä¸ºå­—å…¸åˆ—è¡¨æ—¶ï¼Œæ­¤å‚æ•°è¢«å¿½ç•¥ã€‚
    """
    
    provider_name = get_current_provider_name()
    provider_config = get_current_provider_config()
    
    api_key = (provider_config.get('api_key') or '').strip()
    api_url = (provider_config.get('api_url') or '').strip()
    model_name = (provider_config.get('model') or '').strip()

    # å¯¹äº Geminiï¼Œç›´æ¥ä½¿ç”¨ç³»ç»Ÿç¯å¢ƒå˜é‡ GEMINI_API_KEY
    if provider_name == 'gemini':
        # Gemini ä½¿ç”¨ç³»ç»Ÿç¯å¢ƒå˜é‡ï¼Œä¸éœ€è¦åœ¨è¿™é‡Œæ£€æŸ¥ API key
        pass
    else:
        # å¯¹äºå…¶ä»–æä¾›å•†ï¼Œéœ€è¦ API key å’Œ URL
        if not api_key or not api_url:
            return f"Error: API key or URL is not configured for {provider_name}. Please set it in Settings > API."

    try:
        if provider_name == 'deepseek':
            return _call_deepseek_api(messages, api_key, api_url, model_name)
        elif provider_name == 'gemini':
            return _call_gemini_api_with_context(messages, api_key, model_name, conversation_id, files, is_one_time_attachment)
        else:
            # Default to OpenAI-compatible format
            return _call_openai_compatible_api(messages, api_key, api_url, model_name)
            
    except requests.exceptions.Timeout:
        return f"Error: {provider_name} API request timed out after 120 seconds."
    except Exception as e:
        return f"Error calling {provider_name} API: {str(e)}"


def _call_deepseek_api(messages, api_key, api_url, model_name):
    """Call DeepSeek API (OpenAI-compatible format)."""
    payload = {
        "messages": messages
    }
    if model_name:
        payload["model"] = model_name

    headers = {
        "Authorization": f"Bearer {api_key}",
        "Content-Type": "application/json"
    }
    
    response = requests.post(api_url, json=payload, headers=headers, timeout=120)
    response.raise_for_status()
    data = response.json()
    return data['choices'][0]['message']['content']


def _call_gemini_api_with_context(messages, api_key, model_name, conversation_id=None, files=None, is_one_time_attachment=None):
    """
    Call Google Gemini API with context management (Chat Session).
    æ”¯æŒä¸Šä¸‹æ–‡è®°å¿†å’Œæ–‡ä»¶ä¸Šä¼ çš„ Gemini API è°ƒç”¨ã€‚
    
    æ ¸å¿ƒé€»è¾‘ï¼š
    1. æ£€æŸ¥å¹¶æ¢å¤ Chat Session å†å²ï¼ˆå¦‚æœæœªåˆå§‹åŒ–ï¼‰
    2. Chat Session å†…éƒ¨è‡ªåŠ¨ç»´æŠ¤å†å²è®°å½•
    3. åªéœ€å‘é€æœ€åä¸€æ¡ç”¨æˆ·æ¶ˆæ¯
    4. æ”¯æŒä¸¤ç§æ–‡ä»¶æ¨¡å¼ï¼šä¸´æ—¶ï¼ˆå†…åµŒï¼‰å’ŒæŒä¹…ï¼ˆFile APIï¼‰
    5. å†å²åŒæ­¥ç”± Chat Session ç®¡ç†ï¼Œæ— éœ€æ‰‹åŠ¨å¤„ç†
    
    Args:
        messages: æ¶ˆæ¯åˆ—è¡¨ï¼ˆOpenAIæ ¼å¼ï¼Œç”¨äºå†å²æ¢å¤å’Œæå–æœ€æ–°æ¶ˆæ¯ï¼‰
        api_key: API å¯†é’¥ï¼ˆä»ç¯å¢ƒå˜é‡è·å–ï¼‰
        model_name: æ¨¡å‹åç§°
        conversation_id: å¯¹è¯IDï¼Œç”¨äºç®¡ç†ä¸Šä¸‹æ–‡
        files: æ–‡ä»¶ä¿¡æ¯ï¼ˆå­—å…¸åˆ—è¡¨æˆ–è·¯å¾„åˆ—è¡¨ï¼‰
        is_one_time_attachment: æ–‡ä»¶æ¨¡å¼æ ‡è®°ï¼ˆä»…åœ¨ files ä¸ºè·¯å¾„åˆ—è¡¨æ—¶ä½¿ç”¨ï¼‰
    """
    if not GENAI_AVAILABLE:
        return "Error: Google GenAI SDK is not installed. Please run 'pip install google-generativeai'"
    
    # æ£€æŸ¥æ˜¯å¦å¯ç”¨ä¸Šä¸‹æ–‡ç®¡ç†
    if not GEMINI_CONTEXT_AVAILABLE or not conversation_id:
        # é™çº§åˆ°æ— ä¸Šä¸‹æ–‡æ¨¡å¼
        print("âš ï¸ ä½¿ç”¨æ— ä¸Šä¸‹æ–‡æ¨¡å¼ï¼ˆæœªæä¾› conversation_id æˆ–ä¸Šä¸‹æ–‡ç®¡ç†å™¨ä¸å¯ç”¨ï¼‰")
        return _call_gemini_api_with_sdk(messages, api_key, model_name)
    
    try:
        # è·å–ä¸Šä¸‹æ–‡ç®¡ç†å™¨
        context_manager = get_gemini_context_manager()
        if not context_manager:
            print("âš ï¸ ä¸Šä¸‹æ–‡ç®¡ç†å™¨åˆå§‹åŒ–å¤±è´¥ï¼Œé™çº§åˆ°æ— ä¸Šä¸‹æ–‡æ¨¡å¼")
            return _call_gemini_api_with_sdk(messages, api_key, model_name)
        
        # æ£€æŸ¥ç³»ç»Ÿç¯å¢ƒå˜é‡ GEMINI_API_KEY
        env_api_key = os.getenv('GEMINI_API_KEY')
        if not env_api_key:
            return "Error: GEMINI_API_KEY ç¯å¢ƒå˜é‡æœªè®¾ç½®ã€‚è¯·åœ¨ç³»ç»Ÿä¸­è®¾ç½® GEMINI_API_KEY ç¯å¢ƒå˜é‡ã€‚"
        
        # ç¡®ä¿æ¨¡å‹åç§°æœ‰æ•ˆ
        model_to_use = model_name if model_name else 'gemini-2.5-flash'
        print(f"ğŸ¤– ä½¿ç”¨æ¨¡å‹: {model_to_use} (å¯ç”¨ä¸Šä¸‹æ–‡)")
        
        # ã€æ ¸å¿ƒä¿®æ­£ã€‘åœ¨å‘é€æ¶ˆæ¯å‰ï¼Œæ£€æŸ¥å¹¶æ¢å¤å†å²
        # åªæœ‰å½“ä¸Šä¸‹æ–‡ç®¡ç†å™¨ä¸­ä¸å­˜åœ¨æ­¤ä¼šè¯æ—¶æ‰éœ€è¦æ¢å¤
        if not context_manager.get_chat_session(conversation_id):
            print(f"ğŸ” ä¼šè¯ {conversation_id} ä¸å­˜åœ¨ï¼Œå°è¯•ä»å†å²æ¢å¤...")
            # å¦‚æœ messages åŒ…å«å¤šæ¡å†å²è®°å½•ï¼ˆä¸åªæ˜¯å½“å‰æ¶ˆæ¯ï¼‰ï¼Œåˆ™éœ€è¦æ¢å¤
            if len(messages) > 1:
                # æ’é™¤æœ€åä¸€æ¡æ¶ˆæ¯ï¼ˆè¿™æ˜¯å½“å‰è¦å‘é€çš„ï¼‰
                history_to_restore = messages[:-1]
                if history_to_restore:
                    print(f"ğŸ“š æ¢å¤ {len(history_to_restore)} æ¡å†å²è®°å½•...")
                    try:
                        context_manager.restore_chat_history(
                            conversation_id=conversation_id,
                            messages=history_to_restore,
                            model=model_to_use
                        )
                    except Exception as e:
                        print(f"âš ï¸ å†å²æ¢å¤å¤±è´¥: {str(e)}")
                        # ç»§ç»­æ‰§è¡Œï¼Œåˆ›å»ºæ–°çš„ Chat Session
            else:
                print(f"ğŸ“ è¿™æ˜¯æ–°å¯¹è¯çš„ç¬¬ä¸€æ¡æ¶ˆæ¯")
        else:
            print(f"âœ… ä½¿ç”¨ç°æœ‰çš„ Chat Session")
        
        # ã€æ ¸å¿ƒã€‘æå–æœ€åä¸€æ¡ç”¨æˆ·æ¶ˆæ¯ï¼ˆè¿™æ˜¯æœ¬æ¬¡è¯·æ±‚çš„å”¯ä¸€æ–°å¢å†…å®¹ï¼‰
        # Chat Session ä¼šè‡ªåŠ¨å°†å…¶ä¸å†…éƒ¨å†å²åˆå¹¶
        last_user_message = None
        for msg in reversed(messages):
            if msg['role'] == 'user':
                last_user_message = msg['content']
                break
        
        if not last_user_message:
            return "Error: No user message found."
        
        # åˆ¤æ–­æ˜¯å¦æœ‰æ–‡ä»¶
        if files and len(files) > 0:
            # ã€å¸¦æ–‡ä»¶ã€‘å‘é€æ¶ˆæ¯
            # æ–‡ä»¶ç°åœ¨æ˜¯å­—å…¸åˆ—è¡¨ï¼ŒåŒ…å« path, mode, file_id
            print(f"ğŸ“¤ å‘é€æ¶ˆæ¯åˆ° Chat Sessionï¼ˆå« {len(files)} ä¸ªæ–‡ä»¶ï¼‰")
            
            # åˆ†ç¦»ä¸´æ—¶æ–‡ä»¶å’ŒæŒä¹…æ–‡ä»¶
            temporary_files = [f['path'] for f in files if f.get('mode') == 'temporary']
            persistent_file_ids = [f['file_id'] for f in files if f.get('mode') == 'persistent' and f.get('file_id')]
            
            print(f"ï¿½ ä¸´æ—¶æ–‡ä»¶: {len(temporary_files)} ä¸ª")
            print(f"ğŸ”— æŒä¹…æ–‡ä»¶: {len(persistent_file_ids)} ä¸ª")
            
            for f in files:
                mode_icon = 'ğŸ“„' if f.get('mode') == 'temporary' else 'ğŸ”—'
                print(f"  {mode_icon} {f['path']} (mode={f.get('mode')})")
            
            response_text = context_manager.send_message_with_files(
                conversation_id=conversation_id,
                message=last_user_message,
                file_paths=temporary_files,  # ä¸´æ—¶æ–‡ä»¶è·¯å¾„
                persistent_file_ids=persistent_file_ids,  # æŒä¹…æ–‡ä»¶ID
                model=model_to_use
            )
        else:
            # ã€çº¯æ–‡æœ¬ã€‘å‘é€æ¶ˆæ¯
            # GeminiContextManager.send_message() å†…éƒ¨ä¼šï¼š
            # 1. è·å–æˆ–åˆ›å»ºå¯¹åº”çš„ Chat Session
            # 2. å°†æ¶ˆæ¯æ·»åŠ åˆ°å†…éƒ¨å†å²
            # 3. å‘é€ [å†…éƒ¨å†å² + æœ¬æ¬¡æ¶ˆæ¯] ç»™æ¨¡å‹
            # 4. å°†æ¨¡å‹å›å¤ä¹Ÿæ·»åŠ åˆ°å†…éƒ¨å†å²
            print(f"ğŸ“¤ å‘é€æ¶ˆæ¯åˆ° Chat Session: {last_user_message[:50]}...")
            response_text = context_manager.send_text_message(
                conversation_id=conversation_id,
                message=last_user_message,
                model=model_to_use
            )
        
        print(f"âœ… æ”¶åˆ°å›å¤: {response_text[:50]}...")
        return response_text
        
    except Exception as e:
        print(f"âŒ Gemini ä¸Šä¸‹æ–‡ API é”™è¯¯: {str(e)}")
        import traceback
        traceback.print_exc()
        # é™çº§åˆ°æ— ä¸Šä¸‹æ–‡æ¨¡å¼
        print("âš ï¸ é™çº§åˆ°æ— ä¸Šä¸‹æ–‡æ¨¡å¼")
        return _call_gemini_api_with_sdk(messages, api_key, model_name)


def _call_gemini_api_with_sdk(messages, api_key, model_name):
    """Call Google Gemini API using the official Google GenAI SDK with Client() (æ— ä¸Šä¸‹æ–‡æ¨¡å¼)."""
    if not GENAI_AVAILABLE:
        return "Error: Google GenAI SDK is not installed. Please run 'pip install google-generativeai'"
    
    try:
        # æ£€æŸ¥ç³»ç»Ÿç¯å¢ƒå˜é‡ GEMINI_API_KEY
        env_api_key = os.getenv('GEMINI_API_KEY')
        if not env_api_key:
            return "Error: GEMINI_API_KEY ç¯å¢ƒå˜é‡æœªè®¾ç½®ã€‚è¯·åœ¨ç³»ç»Ÿä¸­è®¾ç½® GEMINI_API_KEY ç¯å¢ƒå˜é‡ã€‚"
        
        print(f"âœ… æ‰¾åˆ°ç³»ç»Ÿç¯å¢ƒå˜é‡ GEMINI_API_KEY")
        
        # ä½¿ç”¨æ‚¨æä¾›çš„å®ä¾‹æ ¼å¼ï¼šfrom google import genai
        from google import genai
        
        # The client gets the API key from the environment variable `GEMINI_API_KEY`.
        client = genai.Client()

        # ç¡®ä¿ä½¿ç”¨ gemini-2.5-flash æ¨¡å‹ï¼ˆæ ¹æ®æ‚¨çš„å¿«é€Ÿå…¥é—¨æŒ‡ä»¤ï¼‰
        # Use the provided model name, or default to 'gemini-2.5-flash'
        model_to_use = model_name if model_name else 'gemini-2.5-flash'
        print(f"ğŸ¤– ä½¿ç”¨æ¨¡å‹: {model_to_use}")

        # ç®€åŒ–æ¶ˆæ¯å¤„ç† - åªå–æœ€åä¸€æ¡ç”¨æˆ·æ¶ˆæ¯
        last_user_message = None
        for msg in reversed(messages):
            if msg['role'] == 'user':
                last_user_message = msg['content']
                break
        
        if not last_user_message:
            return "Error: No user message found."

        print(f"ğŸ“¤ å‘é€æ¶ˆæ¯: {last_user_message[:50]}...")
        
        # ä½¿ç”¨æ‚¨æä¾›çš„æ ¼å¼è°ƒç”¨ API
        response = client.models.generate_content(
            model=model_to_use, 
            contents=last_user_message
        )
        
        if response and response.text:
            print("âœ… æ”¶åˆ°å›å¤")
            return response.text
        else:
            return "Error: Empty response from Gemini."
            
    except Exception as e:
        print(f"âŒ Gemini API é”™è¯¯: {str(e)}")
        return f"Error calling Gemini API: {str(e)}"


def _call_gemini_api(messages, api_key, api_url, model_name):
    """Call Google Gemini API (fallback REST API method)."""
    # Gemini API uses a different format
    # Convert OpenAI format to Gemini format
    
    gemini_messages = []
    for msg in messages:
        if msg['role'] == 'system':
            # Gemini doesn't have system role, prepend to first user message
            continue
        elif msg['role'] == 'user':
            gemini_messages.append({
                "role": "user",
                "parts": [{"text": msg['content']}]
            })
        elif msg['role'] == 'assistant':
            gemini_messages.append({
                "role": "model", 
                "parts": [{"text": msg['content']}]
            })
    
    # Add system message content to first user message if exists
    system_content = ""
    for msg in messages:
        if msg['role'] == 'system':
            system_content = msg['content'] + "\n\n"
            break
    
    if gemini_messages and system_content:
        gemini_messages[0]['parts'][0]['text'] = system_content + gemini_messages[0]['parts'][0]['text']
    
    payload = {
        "contents": gemini_messages,
        "generationConfig": {
            "temperature": 0.7,
            "maxOutputTokens": 2048,
        }
    }
    
    # Build the URL with model and API key
    full_url = f"{api_url}/{model_name}:generateContent?key={api_key}"
    
    headers = {
        "Content-Type": "application/json"
    }
    
    response = requests.post(full_url, json=payload, headers=headers, timeout=120)
    response.raise_for_status()
    data = response.json()
    
    if 'candidates' in data and len(data['candidates']) > 0:
        candidate = data['candidates'][0]
        if 'content' in candidate and 'parts' in candidate['content']:
            return candidate['content']['parts'][0]['text']
    
    return "Error: Invalid response format from Gemini API."


def _call_openai_compatible_api(messages, api_key, api_url, model_name):
    """Call OpenAI-compatible API (fallback for other providers)."""
    payload = {
        "messages": messages
    }
    if model_name:
        payload["model"] = model_name

    headers = {
        "Authorization": f"Bearer {api_key}",
        "Content-Type": "application/json"
    }
    
    response = requests.post(api_url, json=payload, headers=headers, timeout=120)
    response.raise_for_status()
    data = response.json()
    return data['choices'][0]['message']['content']


# Keep the old function name for backward compatibility
def get_deepseek_reply(messages):
    """Backward compatibility function."""
    return get_ai_reply(messages)

def get_topic_from_reply(ai_response):
    """
    é€šè¿‡ä¸€ä¸ªç‰¹æ®Šçš„APIè¯·æ±‚ï¼Œä»AIå›å¤å†…å®¹ä¸­æå–ä¸€ä¸ªç®€çŸ­çš„å¯¹è¯ä¸»é¢˜ã€‚
    ç‰¹åˆ«é€‚ç”¨äºåŒ…å«å›¾ç‰‡åˆ†æã€æ–‡æ¡£åˆ†æç­‰AIç”Ÿæˆå†…å®¹çš„æƒ…å†µã€‚
    """
    messages = [
        {"role": "system", "content": "ä½ æ˜¯æ ‡é¢˜ç”ŸæˆåŠ©æ‰‹ã€‚æ ¹æ®AIå›å¤å†…å®¹ç”Ÿæˆ3ä¸ªæ ‡é¢˜ï¼Œæ¯ä¸ª5å­—ä»¥å†…ï¼Œç”¨é€—å·åˆ†éš”ã€‚ç¤ºä¾‹æ ¼å¼ï¼šè§†é¢‘åˆ†æ,å†…å®¹è§£è¯»,å¤šåª’ä½“è®¨è®ºã€‚åªè¿”å›æ ‡é¢˜ï¼Œä¸è¦ç†ç”±ã€ä¸è¦æ¢è¡Œã€ä¸è¦åºå·ã€ä¸è¦å…¶ä»–ä»»ä½•å†…å®¹ã€‚"},
        {"role": "user", "content": f"AIå›å¤å†…å®¹ï¼š{ai_response[:200]}"}  # åªå–å‰200å­—é¿å…è¿‡é•¿
    ]
    
    try:
        reply = get_ai_reply(messages)
        # æ¸…ç†è¿”å›å†…å®¹
        clean_reply = reply.strip().replace('\n', ' ').replace('\r', '')
        
        # è§£ææ ‡é¢˜ï¼ˆæŒ‰é€—å·æˆ–é¡¿å·åˆ†éš”ï¼‰
        titles = []
        for separator in [',', 'ï¼Œ', 'ã€']:
            if separator in clean_reply:
                titles = [t.strip() for t in clean_reply.split(separator)]
                break
        
        # å¦‚æœæ²¡æœ‰åˆ†éš”ç¬¦ï¼Œç›´æ¥ä½¿ç”¨æ•´ä¸ªå›å¤
        if not titles:
            titles = [clean_reply]
        
        # è¿‡æ»¤å’Œæ¸…ç†æ ‡é¢˜
        valid_titles = []
        for t in titles:
            # ç§»é™¤åºå·ã€æ ‡ç‚¹ã€å¼•å·ç­‰
            t = t.replace('"', '').replace("'", '').replace("ã€‚", '').replace('*', '')
            t = t.replace('**', '').replace('ã€Š', '').replace('ã€‹', '')
            # ç§»é™¤æ•°å­—åºå·
            import re
            t = re.sub(r'^\d+[\.\ã€]?\s*', '', t)
            t = t.strip()
            
            # åªä¿ç•™5ä¸ªå­—ä»¥å†…çš„æ ‡é¢˜
            if t and len(t) <= 5:
                valid_titles.append(t)
        
        if valid_titles:
            # éšæœºé€‰æ‹©ä¸€ä¸ªæ ‡é¢˜
            import random
            selected_title = random.choice(valid_titles)
            print(f"[OK] å¯¹è¯æ ‡é¢˜: {selected_title}")
            return selected_title
        else:
            # å¦‚æœæ²¡æœ‰æœ‰æ•ˆæ ‡é¢˜ï¼Œä»AIå›å¤ä¸­æå–å…³é”®è¯
            words = ai_response[:20].split()
            fallback = words[0] if words else "æ–°å¯¹è¯"
            print(f"[OK] å¯¹è¯æ ‡é¢˜: {fallback}")
            return fallback[:5]  # æœ€å¤š5ä¸ªå­—
            
    except Exception as e:
        print(f"[ERROR] è·å–å¯¹è¯ä¸»é¢˜å¤±è´¥: {e}")
        return "æ–°å¯¹è¯"